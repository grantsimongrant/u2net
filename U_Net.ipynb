{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VidushiBhatia/U-Net-Implementation/blob/main/U_Net_for_Image_Segmentation_From_Scratch_Using_TensorFlow_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1u4Ib9FEK3d"
      },
      "source": [
        "# U-Net 图像分割\n",
        "\n",
        "本notebook实现了U-Net，使用以下资源：\n",
        "* **算法**：Ronnerberger等人，[U-Net](https://arxiv.org/abs/1505.04597)用于生物医学图像分割的卷积神经网络\n",
        "* **数据集**：[oxford iiit宠物数据集](https://www.kaggle.com/tanlikesmath/the-oxfordiiit-pet-dataset)（由Kaggle发布）\n",
        "* **使用的库**：TensorFlow，NumPy，scikit-learn，python-Pillow，imageio，matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmKbyf-METZh",
        "outputId": "20209759-e0f3-4afd-e960-48c1028ecac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "已加载到 /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SAkwUHEEK3s"
      },
      "source": [
        "# 代码分析\n",
        "\n",
        "- [1 - 包](#1)\n",
        "- [2 - 辅助函数用于数据处理](#2)\n",
        "    - [2.1 - 加载数据](#2.1)\n",
        "    - [2.2 - 预处理数据](#2.2)\n",
        "    - [2.3 - 数据可视化](#2.3)\n",
        "- [3 - 构建U-Net模型](#3)\n",
        "    - [3.1 - U-Net架构](#3.1)\n",
        "    - [3.2 - 损失函数](#3.2)\n",
        "    - [3.3 - 优化器](#3.3)\n",
        "- [4 - 训练模型](#4)\n"
      ]
    }
  ]
}- [4.1 - 数据生成器](#4.1)
    - [4.2 - 训练函数](#4.2)
    - [4.3 - 模型评估](#4.3)
- [5 - 测试模型](#5)]```
对于 file in img:
        # 将图像转换为所需形状的数组（3个通道）
        index = img.index(file)
        path = os.path.join(path1, file)
        single_img = Image.open(path).convert('RGB')
        single_img = single_img.resize((i_h,i_w))
        single_img = np.reshape(single_img,(i_h,i_w,i_c)) 
        single_img = single_img/256.
        X[index] = single_img
        
        # 将掩膜转换为所需形状的数组（1个通道）
        single_mask_ind = mask[index]
        path = os.path.join(path2, single_mask_ind)
        single_mask = Image.open(path)
        single_mask = single_mask.resize((m_h, m_w))
        single_mask = np.reshape(single_mask,(m_h,m_w,m_c))
        single_mask = single_mask - 1 # 确保类别从0开始
        y[index] = single_mask
return X, y

#3 - 构建U-Net结构

## 3.1 - U-Net编码块

def EncoderMiniBlock(inputs, n_filters=32, dropout_prob=0.3, max_pooling=True):
    """
    该块使用多个卷积层、最大池化和ReLU激活函数来创建学习架构。
    可以添加dropout以进行正则化，以防止过拟合。
    该块返回下一层的激活值和用于解码器的跳跃连接。
    """
    # 使用2个带有ReLU激活函数和HeNormal初始化的卷积层
    # 适当的初始化可以防止梯度爆炸和消失问题
    # 'Same' padding将卷积层的输入填充，使得输出具有相同的高度和宽度（因此大小不会减小）
    conv = Conv2D(n_filters,
                  3,
                  activation='relu',
                  padding='same',
                  kernel_initializer='HeNormal')(inputs)
    conv = Conv2D(n_filters,
                  3,
                  activation='relu',
                  padding='same',
                  kernel_initializer='HeNormal')(conv)

    # 添加最大池化层
    if max_pooling:
        pool = MaxPooling2D(pool_size=(2, 2))(conv)
        return pool, conv
    else:
        return conv, conv```python
def DecoderMiniBlock(prev_layer_input, skip_layer_input, n_filters=32):
    \"""
    返回包含解码器块内容的字符串
    \"\"\"
    
    # 解码层将来自对应编码层的信息与更早阶段的跳跃连接结合起来
    # 编码层是在编码块中定义的
    \"""up_conv = tf.keras.layers.Conv2DTranspose(filters=n_filters, kernel_size=(3, 3), strides=(2, 2), padding='same')(prev_layer_input)

# 将跳跃连接与解码器层的输出合并
merge = tf.keras.layers.Concatenate()([up_conv, skip_layer_input])

conv = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(3, 3), activation='relu', padding='same', kernel_initializer='HeNormal')(merge)

conv = tf.keras.layers.BatchNormalization()(conv, training=False)

if dropout_prob > 0:
    conv = tf.keras.layers.Dropout(dropout_prob)(conv)

if max_pooling:
    next_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv)
else:
    next_layer = conv

skip_connection = conv

return next_layer, skip_connection## 3.3 - 编译U-Net块